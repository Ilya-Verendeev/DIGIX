{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def vector_method1(model, vector_features, new_data):\\n    \\n    index = nmslib.init(space='cosinesimil', method='sw-graph')\\n    nmslib.addDataPointBatch(index, np.arange(model.wv.syn0.shape[0], dtype=np.int32), model.wv.syn0)\\n    index.createIndex({}, print_progress=True)\\n    start = time.time()\\n    items = nmslib.knnQuery(index, 10, king_vec.tolist())\\n    print(time.time() - start)\\n    print([model.wv.index2word[idx] for idx in items])\""
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def vector_method1(model, vector_features, new_data):\n",
    "    \n",
    "    index = nmslib.init(space='cosinesimil', method='sw-graph')\n",
    "    nmslib.addDataPointBatch(index, np.arange(model.wv.syn0.shape[0], dtype=np.int32), model.wv.syn0)\n",
    "    index.createIndex({}, print_progress=True)\n",
    "    start = time.time()\n",
    "    items = nmslib.knnQuery(index, 10, king_vec.tolist())\n",
    "    print(time.time() - start)\n",
    "    print([model.wv.index2word[idx] for idx in items])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_method3(model, vector_features, X_test, N_QUERY_RESULT=10):\n",
    "    \n",
    "    '''new_data - X_test without forward. Data goes through model and becomes a new vector\n",
    "       which we compare with elements in vector_features'''\n",
    "    \n",
    "    new_data = model(X_test)\n",
    "    new_data_np = np.array(new_data)\n",
    "    \n",
    "    vector_features_np = np.array([np.array(vector) for vector in vector_features])\n",
    "    \n",
    "    if vector_features_np.ndim == 1:\n",
    "        vector_features_np = vector_features[:, np.newaxis]\n",
    "      \n",
    "    nbrs = NearestNeighbors(n_neighbors=N_QUERY_RESULT, metric=\"cosine\").fit(vector_features)\n",
    "    \n",
    "    kneighbors = []\n",
    "    for data in new_data_np:\n",
    "        \n",
    "        data = data[np.newaxis, :]\n",
    "        \n",
    "        distances, indices = nbrs.kneighbors(data)\n",
    "        similar_image_indices = indices.reshape(-1)\n",
    "        kneighbors.append(vector_features[similar_image_indices])\n",
    "    \n",
    "    return kneighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    #mean = np.array([0.485, 0.456, 0.406])\n",
    "    #std = np.array([0.229, 0.224, 0.225])\n",
    "    #inp = std * inp + mean\n",
    "    #inp = np.clip(inp, 0, 1)\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "    \n",
    "def visual_kneighbors(kneighbors):\n",
    "    # Расположим картинки рядом\n",
    "    for part in kneighbors:\n",
    "        out = torchvision.utils.make_grid(kneighbors)\n",
    "        imshow(out)     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
